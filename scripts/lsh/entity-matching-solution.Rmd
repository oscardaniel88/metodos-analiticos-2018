---
title: "Tarea LSH: Entity matching"
output: html_notebook
---



En este ejemplo veremos como usar LSH de una manera simple
para encontrar registros
que se refieren al mismo elemento, pero pueden diferir en cómo están
registrados (entity matching).

## Datos

Los [datos](https://dbs.uni-leipzig.de/de/research/projects/object_matching/fever/benchmark_datasets_for_entity_resolution) para este ejempo particular trata con dos fuentes bibliográficas (DBLP, ACM)
de artículos y conferencias de cómputo. La carpeta del repositorio
es datos/similitud/entity-matching.


```{r, warning=FALSE, message=FALSE}
library(tidyverse)
acm <- read_csv('../../datos/similitud/entity_matching/ACM.csv')
dbl <- read_csv('../../datos/similitud/entity_matching/DBLP2.csv')
```

```{r}
head(acm)
head(dbl)
nrow(acm)
nrow(dbl)
```

**Pregunta**: ¿si intentas una aproximación por fuerza bruta, cuántas comparaciones
tendrías que hacer?

**Respuesta*:
```{r}
nrow(acm)*nrow(dbl)
```

## Shingling y hashing

Vamos a poner todos los documentos en una sola lista. Aunque al final
encontremos elementos de la misma fuente en la misma cubeta, podemos
filtrar estos. En este caso escogemos 20 hashes agrupados en 5 bandas, y 
shingles de tamaño 4, y usamos sólo título y autor.

```{r}
acm_1 <- acm %>% select(title, authors) %>% 
        mutate(texto = paste(title, authors, sep = "    "))
dbl_1 <- dbl %>% select(title, authors) %>% 
         mutate(texto = paste(title, authors, sep = "    "))
```

**Pregunta**: ¿por qué incluimos algún espacio en blanco entre título y autor?
**Respuesta*: Para que los shingles no traslapen autor y título. También es posible
hacer shingles por separado de autor y título

```{r}
shingle_chars <- function(string, lowercase = FALSE, k = 4){
  # produce shingles (con repeticiones)
  if(lowercase) {
    string <- str_to_lower(string)
  }
  shingles <- seq(1, nchar(string) - k + 1) %>%
    map_chr(function(x) substr(string, x, x + k - 1))
  shingles
}
```


```{r}
library(textreuse)
minhasher <- minhash_generator(20)
nombres_acm <- paste0("acm-doc-", 1:length(acm_1$texto))
nombres_dbl <- paste0("dbl-doc-", 1:length(dbl_1$texto))
nombres <- c(nombres_acm, nombres_dbl)
texto <- c(acm_1$texto, dbl_1$texto)
names(texto) <- nombres
corpus <- TextReuseCorpus(text = texto,
                          minhash_func = minhasher,
                          tokenizer = shingle_chars, k = 4,
                          progress = FALSE, skip_short = FALSE)

```



```{r}
lsh_conf <- lsh(corpus, bands = 5) 
```


**Pregunta**: Haz una gráfica mostrando qué porcentaje de cada nivel
de similitud tiene probabilidad de ser capturado para este problema.
Explica en qué casos esto sería razonable, y si consideras apropiado
cambia este número.

**Respuesta**: Usamos el código de la clase. Obsérvese que en este
quizá sea mejor una curva más alta alrededor de similitud 0.75, pero 
podemos examinar los datos más adelante para decidir. En esta gráfica
la combinación 5.4 es la que vamos a usar por el momento
```{r}
graficar_curvas <- function(df_br, colour = TRUE){
  r <- df_br$r
  b <- df_br$b
  datos_graf <- data_frame(s = seq(0, 1, 0.01))
  curvas_similitud <- data_frame(b = b, r =r) %>%
                    group_by(r, b) %>%
                    mutate(datos = map2(r, b, function(r, b){
                      datos_graf %>% 
                      mutate(prob = 1 - (1 - s ^ r) ^b)
                    })) %>%
                    unnest
  graf_salida <- ggplot(curvas_similitud, 
                        aes(x = s, y = prob, 
                            colour = as.factor(interaction(b,r)))) +
                 geom_line(size=1.1) + 
                 labs(x = 'similitud', y= 'probablidad de ser candidato',
                      colour = 'b.r') 
  if(colour){
    graf_salida + scale_colour_manual(values=cb_palette)
  }
                 
  graf_salida
}
df <- data_frame(r = c(4, 2), b = c(5,10))
graficar_curvas(df)
```




## Evaluación de candidatos

```{r}
candidatos <- lsh_candidates(lsh_conf)
candidatos <- lsh_compare(candidatos, corpus, jaccard_similarity)
```

```{r}
candidatos <- candidatos %>% arrange(desc(score))
candidatos
```

Podemos ver el contenido de un texto de esta manera:

```{r}
corpus[["acm-doc-1012"]]$content
corpus[["dbl-doc-1767"]]$content

```


**Pregunta**: ¿Cuántas comparaciones tuviste qué hacer (cálculos de similitud)?
**Respuesta**: Alrededor de 2 mil para los parámetros que escogimos


**Pregunta**:  Filtra esta tabla para que
solo contenga pares que vienen de diferentes tablas (acm y dbl).
Considera ahora los elementos con siimilitud uno. ¿Se refieren al
mismo artículo en las dos fuentes? 

```{r}
diferentes <- function(a,b){
  str_sub(a, 1, 3) != str_sub(b, 1, 3)
}
candidatos_2 <- candidatos %>% filter(diferentes(a,b))

tail(candidatos_3 <- candidatos_2 %>% filter(score==1))
candidatos_3
corpus[["acm-doc-1012"]]$content
corpus[["dbl-doc-1767"]]$content

```

**Pregunta**: Ahora considera los elementos 
con similitud más baja que capturaste. Examina varios casos y concluye
si hay pares que no se refieren al mismo artículo, y por qué.

**Respuesta**: Observamos que varios con score bajo no son el mismo artículo

```{r}
tail(candidatos_2)
corpus[["acm-doc-339"]]$content
corpus[["dbl-doc-1596"]]$content
```




**Pregunta**: propón un punto de corte para la tabla de arriba, según tus
observaciones de la pregunta anterior.
**Respuesta**:
```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_2 <- candidatos %>% filter(diferentes(a,b))
candidatos_3 <- candidatos_2 %>% filter(score>0.4)
cand_3_tail <- tail(candidatos_3)
```

```{r}
a <- cand_3_tail$a[1]
b <- cand_3_tail$b[1]
corpus[[a]]$content
corpus[[b]]$content
```

Y algunos autores coinciden, pero son artículos diferentes. Repetimos con 0.6

```{r}
# código filtrando con score > tu_numero, y examinando los elementos
# de similitud más baja
candidatos_2 <- candidatos %>% filter(diferentes(a,b))
candidatos_3 <- candidatos_2 %>% filter(score>0.6)
cand_3_tail <- tail(candidatos_3)
```

```{r}
a <- cand_3_tail$a[1]
b <- cand_3_tail$b[1]
corpus[[a]]$content
corpus[[b]]$content
a <- cand_3_tail$a[2]
b <- cand_3_tail$b[2]
corpus[[a]]$content
corpus[[b]]$content
```

Este punto de corte es mejor. El total de coincidencias es

```{r}
nrow(candidatos_3)
```

**Pregunta**: considerando tus hallazgos, ¿cómo cambiarías el número
de hashes y bandas para mejorar tus resultados? ¿en qué sentido los mejoras?
**Respuesta**: Alrededor de 0.5, 0.6 parace ser un buen punto de corte. Por lo tanto,
sería mejor tener mejor probabilidad de capturar estas similitudes, por ejemplo,
con los siguientes parámetros (que van a requerir hacer más comparaciones para 
quitar falsos positivos):

```{r}
df <- data_frame(r = c(4, 3), b = c(5,12))
graficar_curvas(df) + geom_vline(xintercept = 0.5)
```




**Pregunta** (si tienes tiempo) Evalúa tus resultados con las respuestas
correctas, que están en la carpeta de los datos.

